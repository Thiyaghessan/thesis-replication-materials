sprintf("Standardized before variable has a mean of %.3f  and a S.D. of %.3f", before_mean, before_sd)
sprintf("Standardized after variable has a mean of %.3f  and a S.D. of %.3f", after_mean, after_sd)
View(crime_bal_df)
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 3")
rm(list = ls())
# Variance of Y and X
var_X <- var(P027$Units)
var_Y <- var(P027$Minutes)
# Sum of the difference between all y values and mean y
mean_Y <- mean(P027$Minutes)
sum_meandiff <- sum(P027$Minutes - mean_Y)
# standardize y values and check
P027$y_std <- (P027$Minutes - mean_Y) / sd(P027$Minutes)
mean(P027$y_std)
sd(P027$y_std)
# Compare correlations under 3 methods
corr_method1 <- (1 / (nrow(P027) - 1)) * sum(((P027$Minutes - mean_Y) / sd(P027$Minutes)) *
((P027$Units - mean(P027$Units)) / sd(P027$Units)))
corr_method2 <- cov(P027$Minutes, P027$Units) / (sd(P027$Minutes) * sd(P027$Units))
corr_method3 <- sum((P027$Minutes - mean_Y) * (P027$Units - mean(P027$Units))) /
sqrt(sum((P027$Minutes - mean_Y)^2) * sum((P027$Units - mean(P027$Units))^2))
round(corr_method1, 3) == round(corr_method2, 3) & round(corr_method2, 3) == round(corr_method3, 3)
# Compare 3 formulas for beta 1 estimate
betahat_method1 <- sum((P027$Minutes - mean_Y) * (P027$Units - mean(P027$Units))) / sum((P027$Units - mean(P027$Units))^2)
betahat_method2 <- cov(P027$Minutes, P027$Units) / var(P027$Units)
betahat_method3 <- cor(P027$Units, P027$Minutes) * (sd(P027$Minutes) / sd(P027$Units))
round(betahat_method1, 3) == round(betahat_method2, 3) & round(betahat_method2, 3) == round(betahat_method3, 3)
# Recreate regression outputs in Table 2.9
repair_mod <- lm(P027$Minutes ~ P027$Units)
summary(repair_mod)
# Obtain coefficients for 4 regression models
# beta 1
beta_1 <- function(x, y){
sum((y - mean(y)) * (x - mean(x))) / sum((x - mean(x))^2)
}
verify <- function(a, b, c, d){
round(a, 2) == round(b, 2) &
round(b, 2) == round(c, 2) &
round(c, 2) == round(d, 2)
}
verify(beta_1(P025b$X1, P025b$Y1),
beta_1(P025b$X2, P025b$Y2),
beta_1(P025b$X3, P025b$Y3),
beta_1(P025b$X4, P025b$Y4))
# beta 0
beta_0 <- function(x, y){
mean(y) - beta_1(x, y) * mean(x)
}
verify(beta_0(P025b$X1, P025b$Y1),
beta_0(P025b$X2, P025b$Y2),
beta_0(P025b$X3, P025b$Y3),
beta_0(P025b$X4, P025b$Y4))
# Check if all 4 correlations are equal
correl <- function(x, y){
sum((y - mean(y)) * (x - mean(x))) /
sqrt(sum((y - mean(y))^2) * sum((x - mean(x))^2))
}
verify(correl(P025b$X1, P025b$Y1),
correl(P025b$X2, P025b$Y2),
correl(P025b$X3, P025b$Y3),
correl(P025b$X4, P025b$Y4))
# Verify R-Square values are identical
rsquare <- function(x, y){
yhats = beta_0(x, y) + beta_1(x, y) * x
ssr = sum((yhats - mean(y))^2)
sst = sum((y - mean(y))^2)
ssr / sst
}
verify(rsquare(P025b$X1, P025b$Y1),
rsquare(P025b$X2, P025b$Y2),
rsquare(P025b$X3, P025b$Y3),
rsquare(P025b$X4, P025b$Y4))
tstat_b1 <- function(x, y, b1){
yhats = beta_0(x, y) + beta_1(x, y) * x
sigma = sqrt(sum((y - yhats)^2) / (length(x) - 2))
se = sigma / (sqrt ( sum((x - mean(x))^2)))
(beta_1(x, y) - b1) / se
}
verify(tstat_b1(P025b$X1, P025b$Y1, 0),
tstat_b1(P025b$X2, P025b$Y2, 0),
tstat_b1(P025b$X3, P025b$Y3, 0),
tstat_b1(P025b$X4, P025b$Y4, 0))
cov(P049$Wife, P049$Husband)
# Convert cm to inches and find covariance
cov(P049$Husband * 0.393701,
P049$Wife * 0.393701)
cor(P049$Husband, P049$Wife)
ggplot(P049,
aes(x = Husband, y = Wife)) +
geom_point() +
labs(title = "Scatter Plot of Heights of Husbands and Wives") +
xlab("Husband Heights") +
ylab("Wives' Heights") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
cor(P049$Husband * 0.393701,
P049$Wife * 0.393701)
cor(P049$Husband,
P049$Husband - 5)
height_mod <- lm(P049$Wife ~ P049$Husband)
summary(height_mod)
tstat_b1(P049$Husband, P049$Wife, 0)
# Function to calculate test statistic for beta 0
tstat_b0 <- function(x, y, b0){
yhats = beta_0(x, y) + beta_1(x, y) * x
sigma = sqrt(sum((y - yhats)^2) / (length(x) - 2))
se = sigma * sqrt( (1 / length(x)) + (mean(x)^2) / sum((x - mean(x))^2))
(beta_0(x, y) - b0) / se
}
tstat_b0(P049$Husband, P049$Wife, 0)
P049$husb_std <- (P049$Husband - mean(P049$Husband)) / sd(P049$Husband)
P049$wife_std <- (P049$Wife - mean(P049$Wife)) / sd(P049$Wife)
abs(tstat_b1(P049$husb_std, P049$wife_std, 1))
summary(lm(P049$wife_std ~ P049$husb_std))
newspaper.lm <- lm(Sunday ~ Daily, data = P050)
summary(newspaper.lm)
confint(newspaper.lm)
x0 = data.frame(Daily = 500)
predict(newspaper.lm, x0, interval = "confidence")
x0 = data.frame(Daily = 500)
predict(newspaper.lm, x0, interval = "prediction")
# Load in data and preprocess it to have a before/after split
crime_df <- read.csv("crime.csv")
crime_df <- crime_df %>%
mutate(date = as.Date(date, format = "%Y-%m-%d"),
post_gfc = ifelse(date < "2008-01-01", 0, 1),
arrest_count = as.numeric(arrest_count)) %>%
select(post_gfc, arrest_count, primary_type) %>%
group_by(primary_type, post_gfc) %>%
summarize(arrest_count = sum(arrest_count))
# balance the data
crime_bal_df <- crime_df %>%
group_by(primary_type) %>%
filter(n() == 2)
# separate dataframe with arrest counts before GFC
pre_gfc_df <- crime_bal_df %>%
filter(post_gfc == 0)
# standardize arrest counts
pre_gfc_std <- (pre_gfc_df$arrest_count - mean(pre_gfc_df$arrest_count)) / sd(pre_gfc_df$arrest_count)
# repeat for post GFC
post_gfc_df <- crime_bal_df %>%
filter(post_gfc == 1)
post_gfc_std <- (post_gfc_df$arrest_count - mean(post_gfc_df$arrest_count)) / sd(post_gfc_df$arrest_count)
# Perform hypothesis test
tstat_b1(pre_gfc_std, post_gfc_std, 0.5)
beta_1(pre_gfc_std, post_gfc_std)
# Function to calculate T-statistic for beta_1
tstat_b1 <- function(x, y, b1){
yhats = beta_0(x, y) + beta_1(x, y) * x
sigma = sqrt(sum((y - yhats)^2) / (length(x) - 2))
se = sigma / (sqrt ( sum((x - mean(x))^2)))
(beta_1(x, y) - b1) / se
}
# Function to calculate S.E. for beta_1
se_b1 <- function(x, y){
yhats = beta_0(x, y) + beta_1(x, y) * x
sigma = sqrt(sum((y - yhats)^2) / (length(x) - 2))
sigma / (sqrt ( sum((x - mean(x))^2)))
}
verify(tstat_b1(P025b$X1, P025b$Y1, 0),
tstat_b1(P025b$X2, P025b$Y2, 0),
tstat_b1(P025b$X3, P025b$Y3, 0),
tstat_b1(P025b$X4, P025b$Y4, 0))
se_b1(pre_gfc_std, post_gfc_std)
(0.98946 - 0.5) / 0.028403
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 4")
rm(list = ls())
# Pairwise correlations
df <- P076
View(df)
View(df)
round(cor(df), 2)
cor_table <- table(round(cor(df), 2))
# Pairwise correlations
df <- P076
cor_table <- table(round(cor(df), 2))
cor_table
cor_table <- data.frame(round(cor(df), 2))
View(cor_table)
View(cor_table)
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
library(kableExtra)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 4")
rm(list = ls())
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_df %>%
kbl() %>%
kable_styling()
cor_df %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod1, mod3)
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
library(kableExtra)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 4")
rm(list = ls())
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_df %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
# Fit 3 models to the data
mod1 <- lm(F ~ P1, data = df)
mod2 <- lm(F ~ P2, data = df)
mod3 <- lm(F ~ P1 + P2, data = df)
anova(mod1, mod3)
# Fit 3 models to the data
mod1 <- lm(F ~ P1, data = df)
mod2 <- lm(F ~ P2, data = df)
mod3 <- lm(F ~ P1 + P2, data = df)
anova(mod1, mod3) %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod1, mod3) %>%
kbl(label = "ANOVA between Model 1 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod1, mod3) %>%
kbl(caption = "ANOVA between Model 1 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod2, mod3) %>%
kbl(caption = "ANOVA between Model 2 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
# Fit 3 models to the data
mod1 <- lm(F ~ P1, data = df)
mod2 <- lm(F ~ P2, data = df)
mod3 <- lm(F ~ P1 + P2, data = df)
anova(mod1, mod3) %>%
kbl(caption = "ANOVA between Model 1 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
library(kableExtra)
library(stargazer)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 4")
rm(list = ls())
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_df %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
# Fit 3 models to the data
mod1 <- lm(F ~ P1, data = df)
mod2 <- lm(F ~ P2, data = df)
mod3 <- lm(F ~ P1 + P2, data = df)
anova(mod1, mod3) %>%
kbl(caption = "ANOVA between Model 1 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
stargazer(mod1, mod2, mod3, type="latex",
dep.var.labels= "F",
covariate.labels=c("P1", "P2"),
out="models.txt")
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
library(kableExtra)
library(stargazer)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 4")
rm(list = ls())
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_df %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
# Fit 3 models to the data
mod1 <- lm(F ~ P1, data = df)
mod2 <- lm(F ~ P2, data = df)
mod3 <- lm(F ~ P1 + P2, data = df)
stargazer(mod1, mod2, mod3, type="latex",
dep.var.labels= "F",
covariate.labels=c("P1", "P2"),
out="models.txt")
anova(mod1, mod3) %>%
kbl(caption = "ANOVA between Model 1 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod2, mod3) %>%
kbl(caption = "ANOVA between Model 2 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
library(linearHypothesis)
library(car)
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
library(kableExtra)
library(stargazer)
library(car)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 4")
rm(list = ls())
linearHypothesis(mod1, "(Intercept) = 0") %>%
kbl(caption = "Model 1") %>%
kable_classic(full_width = F, html_font = "Cambria")
linearHypothesis(model1, "(Intercept) = 0") %>%
kbl(caption = "Model 1") %>%
kable_classic(full_width = F, html_font = "Cambria")
knitr::opts_chunk$set(echo = TRUE)
library(stat224)
library(ggplot2)
library(kableExtra)
library(stargazer)
library(car)
setwd("C:/Users/thiya/OneDrive/Uchicago/spring_23/regression/week 4")
rm(list = ls())
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_df %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
# Fit 3 models to the data
mod1 <- lm(F ~ P1, data = df)
mod2 <- lm(F ~ P2, data = df)
mod3 <- lm(F ~ P1 + P2, data = df)
stargazer(mod1, mod2, mod3, type="latex",
dep.var.labels= "F",
covariate.labels=c("P1", "P2"),
out="models.txt")
anova(mod1, mod3) %>%
kbl(caption = "ANOVA between Model 1 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod2, mod3) %>%
kbl(caption = "ANOVA between Model 2 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
linearHypothesis(mod1, "(Intercept) = 0") %>%
kbl(caption = "Model 1") %>%
kable_classic(full_width = F, html_font = "Cambria")
linearHypothesis(mod2, "(Intercept) = 0") %>%
kbl(caption = "Model 2") %>%
kable_classic(full_width = F, html_font = "Cambria")
linearHypothesis(mod3, "(Intercept) = 0") %>%
kbl(caption = "Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod1) %>%
kbl(caption = "ANOVA between Model 1 and Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
stargazer(anova(mod1), anova(mod2), anova(mod3), type="latex",
dep.var.labels= "F",
covariate.labels=c("P1", "P2"),
out="models2.txt")
stargazer(anova(mod1), anova(mod2), anova(mod3), type="latex",
dep.var.labels= "F",
covariate.labels=c("P1", "P2", "Residuals"),
out="models2.txt")
anova(mod3) %>%
kbl(caption = "ANOVA for Model 3") %>%
kable_classic(full_width = F, html_font = "Cambria")
anova(mod2) %>%
kbl(caption = "ANOVA for Model 2") %>%
kable_classic(full_width = F, html_font = "Cambria")
View(df)
View(df)
38.51128/296.8300
2094.7486/219.51281
8.32^2
(1848.76 * 18) / 69.222
480.74/18
-23.4325/12.74
8.32*0.1528
1848.76/(1848.76 + 480.74)
(480.74/18) / ( (1848.76 + 480.74) / 19 )
1 - ( (480.74/18) / ( (1848.76 + 480.74) / 19 ) )
sqrt( (480.74 / 18) )
1848.76/19
( (sqrt(0.79363) / (sqrt(97.303) * 1.2713) ) ^ (1/3) ) ^ 2
sqrt(0.79363) / (sqrt(97.303) * 1.2713)
0.07103917^(1/3)
0.414^2
9^(1/3)
27^(1/3)
sqrt(0.79363)
sqrt(97.303)
0.8908591/(9.864228*1.2713)
0.07103917^(1/3)
(0.07103917^(1/3))^2
0.4141579^2
( (sqrt(0.79363) / (sqrt(122.605) * 1.2713) ) ^ (1/3) ) ^ 2
sqrt(122.605)
sqrt(122.605) * 0.79363
(sqrt(122.605) * 0.79363) / 1.2713
6.912325^2
(sqrt(122.605) * sqrt(0.79363)) / 1.2713
((sqrt(122.605) * sqrt(0.79363)) / 1.2713 )^2
1.2690/0.5877
((38460756-22657938) / 4) / (22657938 / 88)
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_table <- cor_df %>%
kbl(format = "latex") %>%
kable_classic(full_width = T, html_font = "Cambria")
cor_table
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_table <- cor_df %>%
kbl(format = "latex") %>%
kable_classic(full_width = F, html_font = "Cambria")
cor_table
# Pairwise correlations
df <- P076
cor_df <- data.frame(round(cor(df), 2))
cor_table <- cor_df %>%
kbl(format = "latex")
cor_table
anova(mod1) %>%
kbl(caption = "ANOVA for Model 1") %>%
kable_classic(full_width = F, html_font = "Cambria")
rm(list = ls()) # Clear Environment
setwd("C:/Users/thiya/OneDrive/Uchicago/thesis/data") # Set working directory to where the data files are located
library(dplyr)
library(tidyverse)
library(igraph)
library(kableExtra)
library(intergraph)
library(ergm)
library(texreg)
library(stringr)
windowsFonts("Arial" = windowsFont("Arial")) # Set font for plots
rm(list = ls()) # Clear Environment
setwd("C:/Users/thiya/OneDrive/Uchicago/thesis/data") # Set working directory to where the data files are located
library(dplyr)
library(tidyverse)
library(igraph)
library(kableExtra)
library(intergraph)
library(ergm)
library(texreg)
library(stringr)
windowsFonts("Arial" = windowsFont("Arial")) # Set font for plots
# Import csv containing information on podcasts
pod_df <- read.csv("podcast_hosts.csv") # Data on podcasts
setwd("C:/Users/thiya/OneDrive/Uchicago/thesis/data")
# Import csv containing information on podcasts
pod_df <- read.csv("podcast_hosts.csv") # Data on podcasts
setwd("C:/Users/thiya/OneDrive/Uchicago/thesis/data")
# Import csv containing information on podcasts
pod_df <- read.csv("podcast_hosts.csv") # Data on podcasts
pod_df <- read.csv("podcast_hosts.csv")
rm(list = ls()) # Clear Environment
knitr::opts_knit$set(root.dir = "C:/Users/thiya/OneDrive/Uchicago/thesis/data") # Set working directory to where the data files are located
library(dplyr)
library(tidyverse)
library(igraph)
library(kableExtra)
library(intergraph)
library(ergm)
library(texreg)
library(stringr)
windowsFonts("Arial" = windowsFont("Arial")) # Set font for plots
# Import csv containing information on podcasts
pod_df <- read.csv("podcast_hosts.csv") # Data on podcasts
rm(list = ls()) # Clear Environment
setwd("C:/Users/thiya/OneDrive/Uchicago/thesis/data") # Set working directory to where the data files are located
library(dplyr)
library(tidyverse)
library(igraph)
library(kableExtra)
library(intergraph)
library(ergm)
library(texreg)
library(stringr)
windowsFonts("Arial" = windowsFont("Arial")) # Set font for plots
rm(list = ls()) # Clear Environment
setwd("C:/Users/thiya/OneDrive/Uchicago/thesis/data") # Set working directory to where the data files are located
knitr::opts_knit$set(root.dir = "C:/Users/thiya/OneDrive/Uchicago/thesis/data")
library(dplyr)
library(tidyverse)
library(igraph)
library(kableExtra)
library(intergraph)
library(ergm)
library(texreg)
library(stringr)
windowsFonts("Arial" = windowsFont("Arial")) # Set font for plots
# Import csv containing information on podcasts
pod_df <- read.csv("podcast_hosts.csv") # Data on podcasts
pod_bias_df <- read.csv("podcast_bias.csv") # Data on the level of Bias
hosts_df <- read.csv("podcast_hostattribs.csv") # Data on the podcast hosts' occupations/source of fame
# Merge dataframes
nodes_df <- left_join(pod_df, pod_bias_df, by = "podcasts")
# Summarise the number of unique distributors present in the dataset
distrib_df <- nodes_df %>%
group_by(parent) %>%
summarise(count = n())
# Isolate distributors who own/represent more than one podcast in the dataset
distributors <- distrib_df$parent[distrib_df$count > 1]
# Add this information to nodes_df and recode other variables accordingly
nodes_df <- nodes_df %>%
mutate(distributor = ifelse(parent %in% distributors, parent,
ifelse(parent != "Independent", "Single Company", "Independent")),
bias_ratio = numbiased / (numbiased + numunbiased),
bias_ratio = ifelse(is.nan(bias_ratio), mean(bias_ratio, na.rm = TRUE), bias_ratio),
bias_ratio = ifelse(bias_ratio > 0, bias_ratio, mean(bias_ratio)),
id_code = ifelse(main_ideology == "reactionary", 1,
ifelse(main_ideology == "conservative", 2,
ifelse(main_ideology == "moderate", 3,
ifelse(main_ideology == "liberal", 4,
ifelse(main_ideology == "radical", 5, 6))))))
